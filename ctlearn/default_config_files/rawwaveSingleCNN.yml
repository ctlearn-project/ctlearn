Data:
    mode: 'mono'
    waveform_settings:
        waveform_type: 'raw'
        waveform_sequence_length: 20
        waveform_max_from_simulation: False
        waveform_format: 'timechannel_last'
        waveform_r0pedsub: True
    mapping_settings:
        mapping_method:
            'LSTCam': 'bilinear_interpolation'
            'FlashCam': 'bilinear_interpolation'
            'NectarCam': 'bilinear_interpolation'
            'DigiCam': 'bilinear_interpolation'
            'CHEC': 'oversampling'
            'SCTCam': 'oversampling'
            'LSTSiPMCam': 'bilinear_interpolation'
            'MAGICCam': 'bilinear_interpolation'
        padding:
            'LSTCam': 2
            'FlashCam': 2
            'NectarCam': 2
            'DigiCam': 2
            'CHEC': 0
            'SCTCam': 0
            'LSTSiPMCam': 2
            'MAGICCam': 2
Input:
    batch_size_per_worker: 8
    stack_telescope_images: false
Model:
    name: 'SingleCNNWave'
    backbone: {module: 'single_cnn', function: 'single_cnn_model'}
    waveform_engine: {module: 'basic', function: 'conv_block'}
    head: {module: 'head', function: 'standard_head'}
Model Parameters:
    attention: {mechanism: 'Squeeze-and-Excitation', ratio: 16}
    basic:
        conv_block:
            layers:
                - {filters: 32, kernel_size: 3, number: 1}
                - {filters: 32, kernel_size: 3, number: 1}
                - {filters: 64, kernel_size: 3, number: 1}
                - {filters: 128, kernel_size: 3, number: 1}
            max_pool: {size: 2, strides: 2}
            bottleneck: null
            batchnorm: false
    standard_head:
        type: {fc_head: [512, 256], weight: 1.0}
        energy: {fc_head: [512, 256], weight: 1.0}
        direction: {fc_head: [512, 256], weight: 1.0}
Training:
    validation_split: 0.1
    num_epochs: 10
    verbose: 2
    workers: 1
    optimizer: 'Adam'
    adam_epsilon: 1.0e-8
    base_learning_rate: 0.00001
    lr_reducing_patience: 5
    lr_reducing_factor: 0.5
    lr_reducing_mindelta: 0.01
    lr_reducing_minlr: 0.000001
