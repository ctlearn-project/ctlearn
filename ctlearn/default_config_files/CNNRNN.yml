Data:
    mode: 'stereo'
    image_channels: ['image', 'peak_time']
    mapping_settings:
        mapping_method:
            'LSTCam': 'bilinear_interpolation'
            'FlashCam': 'bilinear_interpolation'
            'NectarCam': 'bilinear_interpolation'
            'CHEC': 'oversampling'
            'SCTCam': 'oversampling'
            'LSTSiPMCam': 'bilinear_interpolation'
            'MAGICCam': 'bilinear_interpolation'
        padding:
            'LSTCam': 2
            'FlashCam': 2
            'NectarCam': 2
            'CHEC': 0
            'SCTCam': 0
            'LSTSiPMCam': 2
            'MAGICCam': 2
Input:
    batch_size_per_worker: 16
    concat_telescopes: false
Model:
    name: 'CNNRNN'
    backbone: {module: 'cnn_rnn', function: 'cnn_rnn_model'}
    engine: {module: 'basic', function: 'conv_block'}
    head: {module: 'head', function: 'standard_head'}
Model Parameters:
    attention: {mechanism: 'Squeeze-and-Excitation', ratio: 16}
    basic:
        conv_block:
            layers:
                - {filters: 32, kernel_size: 3, number: 1}
                - {filters: 32, kernel_size: 3, number: 1}
                - {filters: 64, kernel_size: 3, number: 1}
                - {filters: 128, kernel_size: 3, number: 1}
            max_pool: {size: 2, strides: 2}
            bottleneck: null
            batchnorm: false
    standard_head:
        particletype: {fc_head: [], weight: 1.0}
        energy: {fc_head: [], weight: 1.0}
        direction: {fc_head: [], weight: 1.0}
Training:
    validation_split: 0.05
    num_epochs: 5
    verbose: 2
    workers: 1
    optimizer: 'Adam'
    adam_epsilon: 1.0e-8
    base_learning_rate: 0.0001
    lr_reducing_patience: 5
    lr_reducing_factor: 0.5
    lr_reducing_mindelta: 0.01
    lr_reducing_minlr: 0.00001

