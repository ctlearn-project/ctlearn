
Reco: ['energy']

Logging:
    # Path to directory to store TensorFlow model checkpoints and summary plots.
    # A timestamped copy of the configuration file will also be put here.
    # Required string.
    model_directory: '/home/sahil/deeplearning'

Data:
    # Either a list of data file paths,
    # or a path to a file listing data file paths, one per line.
    # Required list or string.
    # Type of examples to load.
    # Optional string. Default: 'mono'
    # Valid options:
    #   - 'mono': single images of one telescope type
    #   - 'stereo': stereoscopic images of events
    mode: 'mono'

    # List of telescope types to load.
    # Valid telescope types:
    #   - 'LST_LST_LSTCam': LST Telescope and Camera
    #   - 'LST_MAGIC_MAGICCam': MAGIC Telescopes
    #   - 'MST_MST_FlashCam': MST Telescope with FlashCAM Camera
    #   - 'MST_MST_NectarCam': MST Telescope with NectarCAM Camera
    #   - 'SST_SCT_SCTCam': SCT Telescope and Camera
    #   - 'SST_ASTRI_ASTRICam': SST-2M ASTRI Telescope and CHECH Camera
    # Camera images from the following telescopes can be read, but writers
    # for the data are not yet available:
    #   - FACT, HESS-I, HESS-II, VERITAS
    # Required list of strings.
    selected_telescope_types: ['LST_LST_LSTCam']

    # Subset of telescope IDs to include of the selected telescope types.
    # Optional list of integer values.
    # Default: load all telescopes of the selected telescope types.
    selected_telescope_ids: [1, 2, 3, 4]

    # Dict of multiplicity selection.
    # Valid options:
    #     - 'telescope_types': int (from above)
    #     - 'Subarray': int (for full array multiplicity)
    # Optinal dict. Not needed for MAGIC data!
    #multiplicity_selection: {"LST_LST_LSTCam": 4}

    # Dict of parameter selections from the DL1 file.
    # The recommended way of applying quality cuts to the data.
    # Only available for mono analysis at the moment.
    # Optional dict.
    parameter_selection: 
        - {col_name: "hillas_intensity", min_value: 50.0}
        - {col_name: "leakage_intensity_width_2", max_value: 0.2}

    # Not the recommended way of applying quality cuts to the data. 
    # PyTables cut condition to apply selection cuts to events.
    # Optional string. Default: don't apply any cuts
    # See https://www.pytables.org/usersguide/condition_syntax.html
    # for explanation of syntax.
    #selection_string: '(true_energy > 1.0) & (true_h_first_int < 20000)'

    # Event selection filters to apply to each data file.
    # Optional list of dictionaries with the following key/value pairs:
    #   - 'path': Optional string. Path to module containing filter.
    #             Default: path to DL1DataHandler
    #   - 'module': Optional string. Name of module containing filter.
    #               Default: 'utils'
    #   - 'name': Required string. Name of filter.
    #   - 'args': Optional dictionary. Arguments to pass to filter using
    #             filter(file, **args). Default: {}
    # Valid filter names are those defined in DL1DataHandler or any defined
    # in the specified path and module.
    #event_selection:
    #    -
    #        name: 'event_intensity_filter'
    #        args: {i_min: 100, i_max: 316}
    #   -
    #       path: '/path/to/my/module/'
    #       module: 'my_filter'
    #       name: 'filter_fn'
    #       args: {'arg1': 'foo', 'arg2': 3.14}

    # Image selection filters to apply to each image (mono mode only).
    # Optional list of dictionaries with the following key/value pairs:
    #   - 'path': Optional string. Path to module containing filter.
    #             Default: path to DL1DataHandler
    #   - 'module': Optional string. Name of module containing filter.
    #               Default: 'utils'
    #   - 'name': Required string. Name of filter.
    #   - 'args': Optional dictionary. Arguments to pass to filter using
    #             filter(file, **args). Default: {}
    # Valid filter names are those defined in DL1DataHandler or any defined
    # in the specified path and module.
    #image_selection:
    #    -
    #        name: 'image_intensity_filter'
    #        args: {i_min: 10, i_max: 31.6}
    #    -
    #        path: '/path/to/my/module/'
    #        module: 'my_filter'
    #        name: 'filter_fn'
    #        args: {'arg1': 'foo', 'arg2': 3.14}

    # Whether to shuffle the examples.
    # Optional Boolean. Default: False
    shuffle: false

    # Seed for shuffling the examples. Only used if shuffle is true.
    # Optional integer. Default: use default random initialization.
    seed: 1234

    # Image channels to load.
    # Optional list of strings. Default: ['image']
    # Valid options are 'image', 'peak_time' 'cleaned_image' and 'clean_peak_time', or whichever columns are in
    # the telescope tables of your data files.
    image_channels: ['image', 'peak_time']

    # Settings passed directly as arguments to ImageMapper.
    # Optional dictionary. Default: {}
    #
    # The camera types supported by ImageMapper that can be used in
    # the settings below are 'ASTRICam', 'CHEC', 'DigiCam', 'FACT',
    # 'FlashCam', 'HESS-I', 'HESS-II', 'LSTCam', 'MAGICCam', 'NectarCam',
    # 'SCTCam', and 'VERITAS'.
    mapping_settings:

        # List of camera types to calculate mapping tables for.
        # Optional list of camera type strings.
        # Default: calculate mapping tables for all supported camera types
        camera_types: ['LSTCam']

        # Algorithm to convert image vectors to rectangular arrays
        # Optional dictionary with string keys and string values.
        # Default: 'oversampling' for all camera types not in the dictionary
        # Valid keys are any camera types supported by ImageMapper.
        # Valid mapping method options (values):
        #   - 'oversampling': Convert each hexagonal pixel to four square
        #       pixels and reweight the charge to realign to a square grid
        #   - 'rebinning': Interpret the intensity as a histogram and rebin
        #       the hexagonal histogram into a square one.
        #   - 'nearest_interpolation': Perform nearest neighbor
        #   - 'bilinear_interpolation': Draw Delaunay triangulation and
        #       perform bilinear interpolation
        #   - 'bicubic_interpolation': Draw Delaunay triangulation and
        #       perform bicubic interpolation
        #   - 'image_shifting': Shift pixels of alternate rows (hexagonal
        #       cameras only)
        #   - 'axial_addressing': Warp images by relabeling axes (hexagonal
        #       cameras only)
        mapping_method:
            'LSTCam': 'bilinear_interpolation'
            'FlashCam': 'bilinear_interpolation'
            'NectarCam': 'bilinear_interpolation'
            'SCTCam': 'oversampling'
            'CHEC': 'oversampling'
            'MAGICCam': 'bilinear_interpolation'

        # Number of padding pixels to add around each edge of the mapped image.
        # A value of 1 will increase both the image height and width by 2, etc.
        # Optional dictionary with camera type string keys and integer values.
        # Default: 0 for any camera type not specified
        padding:
            'LSTCam': 2
            'FlashCam': 1
            'NectarCam': 2
            'SCTCam': 0
            'CHEC': 0
            'MAGICCam': 2

        # Shape of mapped image to return. Used only for mapping methods
        # without a fixed output shape: rebinning, nearest interpolation,
        # bilinear interpolation, bicubic interpolation
        # Optional dictionary with camera type string keys and values that
        # are lists of three integers: (<width>, <length>, <num_channels>)
        interpolation_image_shape:
            'LSTCam': [110, 110, 1]

        # Explicitly set output grid points outside the camera to 0
        # when performing bilinear and bicubic interpolation.
        # Optional Boolean. Default: false
        mask_interpolation: false

    # Auxiliary information to return from the Array Information table.
    # Optional list of strings. Default: return no array info
    # Valid options are columns in the Array_Information table.
    #array_info: ['x', 'y', 'z']

    # Auxiliary information to return from the Events table.
    # Optional list of strings. Default: return no event info
    # Valid options are columns in the Events table.
    # These options have to be in consonance with the 'label_names' in 'Model'.
    event_info: ['true_shower_primary_id', 'true_energy', 'true_alt', 'true_az']

    # Transforms to apply to the data, in order.
    # Optional list of dictionaries with the following key/value pairs:
    #   - 'path': Optional string. Path to module containing Transform.
    #             Default: path to DL1DataHandler
    #   - 'module': Optional string. Name of module containing Transform.
    #               Default: 'processor'
    #   - 'name': Required string. Name of Transform.
    #   - 'args': Optional dictionary. Arguments to pass to transform using
    #             Transform(**args). Default: {}
    # Valid transform names are those defined in DL1DataHandler or any defined
    # in the specified path and module.
    transforms:
        -
            name: 'MCEnergy'
    #   -
    #       path: '/path/to/my/module/'
    #       module: 'my_transform'
    #       name: 'MyTransform'
    #       args: {'arg1': 'foo', 'arg2': 3.14}

    # Whether to validate that the shape and dtype of the processed data
    # matches the example description.
    # Recommended setting is True while developing the network and False
    # during production.
    # Optional Boolean. Default: False
    validate_processor: False

# Settings for the Keras batch generator.
Input:

    # Number of consecutive examples to combine into a batch for a single gpu.
    # Optional integer. Default: 1
    batch_size_per_worker: 32

    # Whether to concatenate the stereo images from an event to feed it
    # to a monoscopic model.
    # Optional boolean. Default: false
    concat_telescopes: false

# Settings for the TensorFlow model. The options in this and the
# Model Parameters section are passed to the Estimator model_fn
# and the user's model function.
Model:

    # Path to directory containing model module.
    # Optional string or null. Default if missing or null is to load
    # CTLearn default models directory: 'installation_path/ctlearn/ctlearn/default_models/'
    #model_directory: '/my/model/path/'

    # Name of the constructed model.
    # Optional string or null.
    name: 'Param_model'

    # Required dictionary containing a module/function pair.
    # Module in model directory and function in module implementing the model.
    # Module and function pairs included with CTLearn:
    #   - {module: 'single_cnn', function: 'single_cnn_model'}: monoscopic
    #       model using a basic convolutional neural network (CNN)
    #       or residual blocks (ResNets)
    #   - {module: 'cnn_rnn', function: 'cnn_rnn_model'}: array model
    #       feeding output of a basic CNN or a ResNet for each  telescope
    #       into a recurrent neural network (RNN)
    backbone: {module: 'param_model', function: 'param_model'}

    # Required dict with keys 'module' and 'function' & string values.
    # Module and function for the CTLearn backbone.
    # Valid options:
    #   - {module: 'basic', function: 'conv_block'}
    #   - {module: 'resnet_engine', function: 'stacked_res_blocks'}
    network: {module: 'basic', function: 'fully_connect'}

    # Optional arguments for the first Conv2D and MaxPool layer
    # before the selected model.
    #init_layer: {filters: 64, kernel_size: 7, strides: 1}
    #init_max_pool: {size: 3, strides: 2}

    # Required dict with keys 'module' and 'function' & string values.
    # Module and function for the CTLearn head.
    # Valid options:
    #   - {module: 'head', function: 'standard_head'}
    head: {module: 'head', function: 'standard_head'}

    # Required string or null.
    # Path to a checkpoint file or model directory from which to load
    # pretrained network weights. If null, don't load any weights.
    pretrained_weights: null

    # Optional float. Default: 0.5
    # Dropout rate of dropout layers in the CNNRNN model.
    dropout_rate: 0.5

# The options in this and the Model section are passed in a dictionary
# called "params" to the model function.
# The config option 'model_directory' above is included in params as well.
# None of these options are accessed anywhere outside the model, so
# arbitrary options may be added here. This permits custom configuration
# of user-provided models.
# Below are listed the configuration options for the CTLearn included
# models, which are only accessed if using those models.
Model Parameters:

    basic:
        fully_connect:
            layers:  [1024, 512, 256, 128, 64]
        conv_block:
            # Required list of dicts with keys 'filters', 'kernel_size' and number
            # with integer values.
            # If number value is not stored will be automatically set to 1
            # Filter dimension and kernel size for the CNN block
            # convolutional layers.
            # Number for the desired number of convolutional layers 
            layers:
                - {filters: 32, kernel_size: 3, number: 1}
                - {filters: 64, kernel_size: 3, number: 1}
                - {filters: 128, kernel_size: 3, number: 1}

            # Required dictionary with keys 'size' and 'strides' and
            # integer values, or null.
            # Max pool size and strides. If null, don't perform any pooling.
            max_pool: {size: 2, strides: 2}

            # Required integer or null.
            # Number of output filters of a final 1x1 convolutional layer.
            # If null, don't include this bottleneck layer.
            bottleneck: null

            # Optional Boolean. Default: false
            # Whether to include a batch normalization layer after each
            # convolutional layer. Exercise caution when using with
            # array-level models.
            batchnorm: false

        fc_head:
            # Required list of integers.
            # Number of units for each fully-connected head dense layer.
            layers: [1024, 512, 256, 128, 64]

            # Optional Boolean. Default: false
            # Whether to include a batch normalization layer after each
            # dense layer.
            batchnorm: false

        conv_head:
            # Required list of dicts with keys 'filters' and 'kernel_size'
            # with integer values.
            # Filter dimension and kernel size for the convolutional
            # network head layers.
            layers:
                - {filters: 64, kernel_size: 3}
                - {filters: 128, kernel_size: 3}
                - {filters: 256, kernel_size: 3}

            # Optional Boolean. Default: true
            # Whether to perform average pooling over spatial dimensions
            # of the convolutional output before calculating final output.
            final_avg_pool: true

            # Optional Boolean. Default: false
            # Whether to include a batch normalization layer after each
            # convolutional layer.
            batchnorm: false

        # Optional float. Default: 0.99
        # Decay parameter for batch normalization layers.
        batchnorm_decay: 0.99

    resnet_engine:
        stacked_res_blocks:
            # Optional string. Default: 'bottleneck'
            # Type of the residual block.
            # Valid options:
            #   - 'basic'
            #   - 'bottleneck'
            residual_block: 'bottleneck'

            # Required list of dicts with keys 'filters' and 'blocks'
            # with integer values.
            # Filter dimension and number of blocks for the ResNet 
            # architecture.
            # Typical ResNet architectures:
            # Thin-ResNet
            #- {filters: 48, blocks: 2}
            #- {filters: 96, blocks: 3}
            #- {filters: 128, blocks: 3}
            #- {filters: 256, blocks: 3}
            # ResNet50
            #- {filters: 64, blocks: 3}
            #- {filters: 128, blocks: 4}
            #- {filters: 256, blocks: 6}
            #- {filters: 512, blocks: 3}
            architecture:
                - {filters: 48, blocks: 2}
                - {filters: 96, blocks: 3}
                - {filters: 128, blocks: 3}
                - {filters: 256, blocks: 3}

    # Dictionary of tasks where the values contain the fully connected layers
    # head of each reconstruction task. The final loss is calculated with a weighted sum 
    # over the individual losses. Currently the weights are constanst values.
    # For the classification task, the class names are passed into the dict
    # in order of class label (0 to n-1).
    standard_head:
        particletype: {class_names: ['proton', 'gamma'], fc_head: [512, 256, 2], weight: 1.0}
        energy: {fc_head: [512, 256, 1], weight: 1.0}
        direction: {fc_head: [512, 256, 2], weight: 1.0}

    # Optional dict of attention mechanisms.
    # Valid options:
    #   Dual attention (Spatial and channel squeeze-and-excitation attention)
    #   - {mechanism: 'Squeeze-and-Excitation', ratio: 16}
    #   Channel Squeeze-and-excitation attention
    #   - {mechanism: 'Channel-Squeeze-and-Excitation', ratio: 4}
    #   Spatial squeeze-and-excitatiom attention
    #   - {mechanism: 'Spatial-Squeeze-and-Excitation'}
    # References:
    # - [Squeeze and Excitation Networks](https://arxiv.org/abs/1709.01507)
    # - [Concurrent Spatial and Channel Squeeze & Excitation in Fully Convolutional Networks](https://arxiv.org/abs/1803.02579)
    attention: {mechanism: 'Squeeze-and-Excitation', ratio: 16}

Training:

    # Optional float. Default: 0.1
    # Randomly chosen fraction of data to set aside for validation.
    validation_split: 0.1

    # Required number of epochs on which to train.
    num_epochs: 20

    # Required string.
    # Valid options: ['Adadelta', 'Adam', 'RMSProp', 'SGD']
    # Optimizer function for training.
    optimizer: 'Adam'

    # Optional float. Required if optimizer is 'Adam', ignored otherwise.
    # Epsilon parameter for the Adam optimizer.
    adam_epsilon: 1.0e-8

    # Required integer.
    # Base learning rate before scaling or annealing.
    base_learning_rate: 0.001

Prediction:

    # Required string if running in predict mode.
    # Name of the file to save predictions.
    file: 'ctlearn_prediction'

    # A dict of either a list of data file paths,
    # or a path to a file listing data file paths, one per line.
    # Required dict of list or string if running in predict mode.
    prediction_file_lists: 
        'prediction_file_list1': '/tmp/dataset/prediction_file_list1.txt'
        'prediction_file_list2': '/tmp/dataset/prediction_file_list2.txt'

    # Save the true labels along with the predictions.
    # Optional Boolearn. Default: false
    save_labels: false

    # Save the example identifiers along with the predictions.
    # Mono mode: obs_id, event_id, tel_id
    # Stereo mode: obs_id, event_id
    # Optional Boolearn. Default: false
    save_identifiers: false

# Optional: used in run_multiple_configurations.py only
Multiple Configurations Settings:
    # Required string.
    # Path to file to save configuration combination for each run for reference.
    run_combinations_path: '/tmp/run_combinations.yml'

    # Optional integer. Default: 1
    # Number of grouped range values to generate. All range values with null
    # num_values are grouped so that random values are generated for each
    # combination of parameters, not for each parameter separately. Ignored for
    # ungrouped range values, that is, where num_values is specified.
    num_grouped_range_values: 5

# Optional: used in run_multiple_configurations.py only
# Each item in this section has the form
# <config_nickname>:
#   config: list of the keys to access the config parameter in config file
#   value_type: one of
#       - 'list': values is a list of possible values
#       - 'range': values is a dictionary as described below
#       - 'grouped': values is a dictionary of <group_name>: value
#   values: list or dictionary as specified by the value_type
#
# The values section for a config option with value_type 'range' has the form:
# values:
#   lower_bound: Required integer. Lower bound of the range.
#   upper_bound: Required integer. Upper bound of the range.
#   spacing: Required string. Valid options:
#       - 'log': generate values uniformly using logarithmic spacing
#       - 'linear': generate values uniformly using linear spacing
#   selection: Required string. Valid options:
#       - 'random': Select values at random from a uniform distribution
#       - 'grid': Select values from an evenly-spaced grid
#   num_values: Required integer or null. Number of values to generate. All
#       range configs with num_values null are grouped together with
#       num_grouped_range_values the total number of values generated. The
#       recommended usage in most cases is to specify num_values for grid
#       selection and set to null for random selection.
Multiple Configurations Values:
    learning_rate:
        config: ['Training', 'base_learning_rate']
        value_type: 'range'
        values:
            lower_bound: 1.0e-6
            upper_bound: 1.0e-3
            spacing: 'log'
            selection: 'random'
            num_values: null
    multiplicity_cut:
        config: ['Data', 'selection_string']
        value_type: 'list'
        values:
            - 'true_energy < 1.0'
            - 'true_energy >= 1.0'
    telescope_type:
        config: ['Data', 'selected_telescope_type']
        value_type: 'grouped'
        values:
            'LST_LST_LSTCam': 'LST_LST_LSTCam'
            'MST_MST_NectarCam': 'MST_MST_NectarCam'
    selected_telescopes:
        config: ['Data', 'selected_telescope_ids']
        value_type: 'grouped'
        values:
            'LST_LST_LSTCam': [1, 2, 3, 4]
            'MST_MST_NectarCam': [30, 31, 32, 33]
    network_type:
        config: ['Model', 'model']
        value_type: 'grouped'
        values:
            CNN_RNN:
                module: 'cnn_rnn'
                function: 'cnn_rnn_model'
    # Not yet implemented!
    telescope_sorting:
        config: ['Data', 'transforms']
        value_type: 'grouped'
        values:
            CNN_RNN: [{name: SortImages, args: {'order': 'size'}}]
            variable_input: null
